{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import random\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# for whatever reason, selenium gets to the end of a page, and keeps trying to click buttons\n",
    "# need to try except this error away\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "\n",
    "# import proxy drivers\n",
    "from selenium.webdriver.common.proxy import Proxy, ProxyType\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "\n",
    "# import async packages\n",
    "import asyncio\n",
    "from proxybroker import Broker\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get \"N_PROXIES\" proxies\n",
    "def get_proxies(N_PROXIES):\n",
    "    # initiate proxy list\n",
    "    proxy_list = []\n",
    "    \n",
    "    # define async function to get proxies\n",
    "    async def show(proxies):\n",
    "        while True:\n",
    "            proxy = await proxies.get()\n",
    "            if proxy is None: break\n",
    "            print('Found proxy: %s' % proxy)\n",
    "            proxy_list.append(proxy)\n",
    "    \n",
    "    # create async loop\n",
    "    proxies = asyncio.Queue()\n",
    "    broker = Broker(proxies)\n",
    "    tasks = asyncio.gather(\n",
    "        broker.find(types=['HTTPS'], limit=N_PROXIES),\n",
    "        show(proxies))\n",
    "    \n",
    "    # run async\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(tasks)\n",
    "    \n",
    "    return proxy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to test a proxy \"TESTS\" times\n",
    "def test_proxy(HOST, PORT, TESTS):\n",
    "    url = \"https://www.rottentomatoes.com\"\n",
    "    \n",
    "    # initialize proxy settings\n",
    "    PROXY = str(HOST) + \":\" + str(PORT)\n",
    "    webdriver.DesiredCapabilities.FIREFOX['proxy'] = {\n",
    "        \"httpProxy\": PROXY,\n",
    "        \"ftpProxy\": PROXY,\n",
    "        \"sslProxy\": PROXY,\n",
    "        \"proxyType\": \"MANUAL\",\n",
    "    }\n",
    "    \n",
    "    # define iter variable, using a flag technique\n",
    "    ITER = 1\n",
    "    \n",
    "    # try to get url, if fail, increase iter\n",
    "    while ITER <= TESTS:\n",
    "        try:\n",
    "            # get the url\n",
    "            driver = webdriver.Firefox()\n",
    "            driver.install_addon('/home/nathanael/Downloads/testdir/noscript/noscript.xpi', temporary=True)\n",
    "            driver.set_page_load_timeout(10)\n",
    "            driver.get(url)\n",
    "            \n",
    "            # let the page load\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # look for ratings to double check if loaded\n",
    "            ratings = driver.find_elements_by_class_name('dynamic-text-list__tomatometer-group')\n",
    "            driver.quit()\n",
    "            \n",
    "            # if successful, set flag to 10, otherwise try again\n",
    "            if ratings:\n",
    "                ITER = 10\n",
    "            else:\n",
    "                ITER += 1\n",
    "        \n",
    "        # failure, increase iter\n",
    "        except:\n",
    "            print(\"failed \" + str(ITER) + \" time(s)\")\n",
    "            ITER += 1\n",
    "            driver.quit()\n",
    "    \n",
    "    # if success, return True, otherwise false\n",
    "    if ITER == 10:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle_proxy(proxies):\n",
    "    # make a copy of the list\n",
    "    proxies_copy = proxies\n",
    "    \n",
    "    # use the flag method\n",
    "    flag = 0\n",
    "    while flag == 0:\n",
    "        # choose random index\n",
    "        rand_ind = random.randrange(len(proxies))\n",
    "        proxy = proxies_copy[rand_ind]\n",
    "        \n",
    "        # test this proxy\n",
    "        if test_proxy(proxy.host, proxy.port, 2):\n",
    "            # if successful, return this proxy\n",
    "            flag = 1\n",
    "            return (proxy, proxies_copy)\n",
    "        \n",
    "        # otherwise, remove it\n",
    "        else:\n",
    "            del proxies_copy[rand_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_links gets all links for movies of genre \"genre\" with score between \"score_min\" and \"score_max\"\n",
    "# input \"score_min\", \"score_max\", and \"genre\" as integers\n",
    "def get_links(score_min, score_max, genre, HOST, PORT):\n",
    "\n",
    "    # create url to scrape links from\n",
    "    url = \"https://www.rottentomatoes.com/browse/dvd-streaming-all?\" + \\\n",
    "        \"minTomato=\" + str(score_min) + \"&maxTomato=\" + str(score_max) + \\\n",
    "        \"&services=amazon;hbo_go;itunes;netflix_iw;vudu;amazon_prime;fandango_now&genres=\" + \\\n",
    "        str(genre) + \"&sortBy=release\"\n",
    "\n",
    "    # initialize empty list to put URLs in\n",
    "    endings = []\n",
    "    \n",
    "    # initialize proxy settings\n",
    "    PROXY = str(HOST) + \":\" + str(PORT)\n",
    "    webdriver.DesiredCapabilities.FIREFOX['proxy'] = {\n",
    "        \"httpProxy\": PROXY,\n",
    "        \"ftpProxy\": PROXY,\n",
    "        \"sslProxy\": PROXY,\n",
    "        \"proxyType\": \"MANUAL\",\n",
    "    }\n",
    "\n",
    "    # open the URL\n",
    "    driver = webdriver.Firefox()\n",
    "    driver.install_addon('/home/nathanael/Documents/ublock.xpi', temporary=True)\n",
    "    driver.install_addon('/home/nathanael/Downloads/testdir/noscript/noscript.xpi', temporary=True)\n",
    "    driver.set_page_load_timeout(180)\n",
    "    driver.get(url)\n",
    "    \n",
    "    # look for button to load all the movies\n",
    "    buttons = driver.find_elements_by_class_name('btn.btn-secondary-rt.mb-load-btn')\n",
    "    \n",
    "    # wait five seconds for the page to load\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # while there are buttons to click, keep clicking them\n",
    "    while(buttons):\n",
    "        try:\n",
    "            buttons[0].click()\n",
    "            \n",
    "            # look for more buttons to click\n",
    "            buttons = driver.find_elements_by_class_name('btn.btn-secondary-rt.mb-load-btn')\n",
    "            time.sleep(2)\n",
    "        except StaleElementReferenceException:\n",
    "            # once we reach bottom of page, break\n",
    "            print(\"Reached bottom of page, scraping links\")\n",
    "            break\n",
    "    \n",
    "    # look for the boxes containing info about the movies\n",
    "    infos = driver.find_elements_by_class_name('movie_info')\n",
    "    for info in infos:\n",
    "        # convert to beautiful soup objects\n",
    "        soup = BeautifulSoup(info.get_attribute('innerHTML'), \"html.parser\")\n",
    "        for link in soup.findAll('a'):\n",
    "            # extract hrefs\n",
    "            endings.append(link.get('href'))\n",
    "\n",
    "    # close the browser once done\n",
    "    driver.quit()\n",
    "    \n",
    "    return endings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PROXIES = 20\n",
    "genres = [1, 2, 4, 5, 6, 8, 9, 10, 11, 13, 18, 14]\n",
    "proxies = get_proxies(N_PROXIES)\n",
    "links_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre in genres:\n",
    "    (proxy, proxies) = cycle_proxy(proxies)\n",
    "    for i in range(5):\n",
    "        score_min = i * 21\n",
    "        score_max = min((i + 1) * 21 - 1, 100)\n",
    "        new_links = get_links(score_min, score_max, genre, proxy.host, proxy.port)\n",
    "        \n",
    "        if new_links:\n",
    "            links_list_2.append(new_links)\n",
    "        else:\n",
    "            print(\"failed \" + str(score_min) + \":\" + str(score_max) + \" of \" + str(genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('links.pkl', 'wb') as f:\n",
    "    pickle.dump(links, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
