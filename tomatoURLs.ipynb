{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import random\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# for whatever reason, selenium gets to the end of a page, and keeps trying to click buttons\n",
    "# need to try except this error away\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "\n",
    "# import proxy drivers\n",
    "from selenium.webdriver.common.proxy import Proxy, ProxyType\n",
    "\n",
    "# import async packages\n",
    "import asyncio\n",
    "from proxybroker import Broker\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get \"N_PROXIES\" proxies\n",
    "def get_proxies(N_PROXIES):\n",
    "    # initiate proxy list\n",
    "    proxy_list = []\n",
    "    \n",
    "    # define async function to get proxies\n",
    "    async def show(proxies):\n",
    "        while True:\n",
    "            proxy = await proxies.get()\n",
    "            if proxy is None: break\n",
    "            print('Found proxy: %s' % proxy)\n",
    "            proxy_list.append(proxy)\n",
    "    \n",
    "    # create async loop\n",
    "    proxies = asyncio.Queue()\n",
    "    broker = Broker(proxies)\n",
    "    tasks = asyncio.gather(\n",
    "        broker.find(types=['HTTPS'], limit=N_PROXIES),\n",
    "        show(proxies))\n",
    "    \n",
    "    # run async\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(tasks)\n",
    "    \n",
    "    return proxy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to test a proxy \"TESTS\" times\n",
    "def test_proxy(HOST, PORT, TESTS):\n",
    "    url = \"https://www.rottentomatoes.com\"\n",
    "    \n",
    "    # initialize proxy settings\n",
    "    PROXY = str(HOST) + \":\" + str(PORT)\n",
    "    webdriver.DesiredCapabilities.FIREFOX['proxy'] = {\n",
    "        \"httpProxy\": PROXY,\n",
    "        \"ftpProxy\": PROXY,\n",
    "        \"sslProxy\": PROXY,\n",
    "        \"proxyType\": \"MANUAL\",\n",
    "    }\n",
    "    \n",
    "    # define iter variable, using a flag technique\n",
    "    ITER = 1\n",
    "    \n",
    "    # try to get url, if fail, increase iter\n",
    "    while ITER <= TESTS:\n",
    "        try:\n",
    "            # get the url\n",
    "            driver = webdriver.Firefox()\n",
    "            driver.set_page_load_timeout(90)\n",
    "            driver.get(url)\n",
    "            \n",
    "            # let the page load\n",
    "            time.sleep(10)\n",
    "            \n",
    "            # look for ratings to double check if loaded\n",
    "            ratings = driver.find_elements_by_class_name('dynamic-text-list__tomatometer-group')\n",
    "            driver.quit()\n",
    "            \n",
    "            # if successful, set flag to 10, otherwise try again\n",
    "            if ratings:\n",
    "                ITER = 10\n",
    "            else:\n",
    "                ITER += 1\n",
    "        \n",
    "        # failure, increase iter\n",
    "        except:\n",
    "            print(\"failed \" + str(ITER) + \" time(s)\")\n",
    "            ITER += 1\n",
    "            driver.quit()\n",
    "    \n",
    "    # if success, return True, otherwise false\n",
    "    if ITER == 10:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle_proxy(proxies):\n",
    "    # make a copy of the list\n",
    "    proxies_copy = proxies\n",
    "    \n",
    "    # use the flag method\n",
    "    flag = 0\n",
    "    while flag == 0:\n",
    "        # choose random index\n",
    "        rand_ind = random.randrange(len(proxies))\n",
    "        proxy = proxies_copy[rand_ind]\n",
    "        \n",
    "        # test this proxy\n",
    "        if test_proxy(proxy.host, proxy.port, 2):\n",
    "            # if successful, return this proxy\n",
    "            flag = 1\n",
    "            return (proxy, proxies_copy)\n",
    "        \n",
    "        # otherwise, remove it\n",
    "        else:\n",
    "            del proxies_copy[rand_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# get_links gets all links for movies of genre \"genre\" with score between \"score_min\" and \"score_max\"\n",
    "# input \"score_min\", \"score_max\", and \"genre\" as integers\n",
    "def get_links(score_min, score_max, genre, HOST, PORT):\n",
    "\n",
    "    # create url to scrape links from\n",
    "    url = \"https://www.rottentomatoes.com/browse/dvd-streaming-all?\" + \\\n",
    "        \"minTomato=\" + str(score_min) + \"&maxTomato=\" + str(score_max) + \\\n",
    "        \"&services=amazon;hbo_go;itunes;netflix_iw;vudu;amazon_prime;fandango_now&genres=\" + \\\n",
    "        str(genre) + \"&sortBy=release\"\n",
    "\n",
    "    # initialize empty list to put URLs in\n",
    "    endings = []\n",
    "    \n",
    "    # initialize proxy settings\n",
    "    PROXY = str(HOST) + \":\" + str(PORT)\n",
    "    webdriver.DesiredCapabilities.FIREFOX['proxy'] = {\n",
    "        \"httpProxy\": PROXY,\n",
    "        \"ftpProxy\": PROXY,\n",
    "        \"sslProxy\": PROXY,\n",
    "        \"proxyType\": \"MANUAL\",\n",
    "    }\n",
    "\n",
    "    # open the URL\n",
    "    driver = webdriver.Firefox()\n",
    "    driver.set_page_load_timeout(180)\n",
    "    driver.get(url)\n",
    "    \n",
    "    # look for button to load all the movies\n",
    "    buttons = driver.find_elements_by_class_name('btn.btn-secondary-rt.mb-load-btn')\n",
    "    \n",
    "    # wait ten seconds for the page to load\n",
    "    time.sleep(10)\n",
    "    \n",
    "    # while there are buttons to click, keep clicking them\n",
    "    while(buttons):\n",
    "        try:\n",
    "            buttons[0].click()\n",
    "            \n",
    "            # look for more buttons to click\n",
    "            buttons = driver.find_elements_by_class_name('btn.btn-secondary-rt.mb-load-btn')\n",
    "            time.sleep(2)\n",
    "        except StaleElementReferenceException:\n",
    "            # once we reach bottom of page, break\n",
    "            print(\"Reached bottom of page, scraping links\")\n",
    "            break\n",
    "    \n",
    "    # look for the boxes containing info about the movies\n",
    "    infos = driver.find_elements_by_class_name('movie_info')\n",
    "    for info in infos:\n",
    "        # convert to beautiful soup objects\n",
    "        soup = BeautifulSoup(info.get_attribute('innerHTML'), \"html.parser\")\n",
    "        for link in soup.findAll('a'):\n",
    "            # extract hrefs\n",
    "            endings.append(link.get('href'))\n",
    "\n",
    "    # close the browser once done\n",
    "    driver.quit()\n",
    "    \n",
    "    return endings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PROXIES = 40\n",
    "genres = [4, 5, 6, 8, 9, 10, 11, 13, 18, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/proxybroker/api.py:97: DeprecationWarning: The loop argument is deprecated since Python 3.8, and scheduled for removal in Python 3.10.\n",
      "  self._on_check = asyncio.Queue(maxsize=max_conn, loop=self._loop)\n",
      "/usr/lib/python3.9/asyncio/queues.py:48: DeprecationWarning: The loop argument is deprecated since Python 3.8, and scheduled for removal in Python 3.10.\n",
      "  self._finished = locks.Event(loop=loop)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Could not get the external IP",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-5f45d9d736dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_proxies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-259dce0b0892>\u001b[0m in \u001b[0;36mget_proxies\u001b[0;34m(N_PROXIES)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# run async\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mproxy_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 raise RuntimeError(\n\u001b[1;32m     97\u001b[0m                     'Event loop stopped before Future completed.')\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_thread_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/proxybroker/api.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(self, types, data, countries, post, strict, dnsbl, limit, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mChanged\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mrequired\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \"\"\"\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_real_ext_ip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_update_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/proxybroker/resolver.py\u001b[0m in \u001b[0;36mget_real_ext_ip\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Could not get the external IP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not get the external IP"
     ]
    }
   ],
   "source": [
    "proxies = get_proxies(N_PROXIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached bottom of page, scraping links\n",
      "Reached bottom of page, scraping links\n"
     ]
    }
   ],
   "source": [
    "for genre in genres:\n",
    "    (proxy, proxies) = cycle_proxy(proxies)\n",
    "    for i in range(8):\n",
    "        score_min = i * 13\n",
    "        score_max = min((i + 1) * 13 - 1, 100)\n",
    "        new_links = get_links(score_min, score_max, genre, proxy.host, proxy.port)\n",
    "        \n",
    "        if new_links:\n",
    "            links_list.append(new_links)\n",
    "        else:\n",
    "            print(\"failed \" + str(score_min) + \":\" + str(score_max) + \" of \" + str(genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
